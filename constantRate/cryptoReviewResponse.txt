Thank you for the reviews and useful feedback.

We use irises to motivate why working for negative minimum usable entropy is important. Biometrics provided the original motivation for fuzzy extractors and irises are the best known biometric via IrisCode.  Yet even IrisCode has negative minimum usable entropy.

However, our constructions do not currently provide security for irises. We believe we provide the first steps in that direction, by introducing techniques that rely on specific properties of a distribution (because we know techniques that work for all distributions of a given entropy cannot be used in the case of negative usable entropy).

Q: Length of the key?
A: In the computational setting, a key can be expanded arbitrarily using a PRG, so the length is not paramount. To get enough length for an initial seed, our constructions can be run multiple times (this is not true for all constructions and cannot be true for information-theoretic constructions). As written, key length of the first construction (4.1) is linear in the number of symbols (not bits) in the input, and key length of the second construction (5.2) is an arbitrary polynomial in the security parameter, which we get to choose.

Q: Practicality of large alphabet and hope for smaller
A: Indeed, a large alphabet is a limitation of our work. Large alphabets do occur in applications: for example, fingerprints (but the metric is more complex than Hamming) or "movie lists" from Juels-Sudan (the metric is set difference). We note that our second construction works for an arbitrary size alphabet, but only achieves negative usable entropy for large alphabets because of limited error-tolerance. This provides hope that the alphabet size can be reduced.  The main obstacle is increasing our supported error tolerance.  

Q: Heavy-duty machinery/efficiency
A: Point obfuscation is practical and can be built from standard assumptions. It does not require indistinguishability obfuscation. For example, it is reasonable to assume that a randomized cryptographic hash function already works (it does in the RO model). As another example, Canetti-Dakdouk build it from Diffie-Hellman with just one exponentiation. So k hashes or exponentiations are reasonable efficiency estimates.

Q: Length of p
A: k obfuscations (e.g., hash values or pairs of group elements). The second construction also stores the sampling bits, \omega(\log^2 k) per key bit (but we can use more efficient samplers).

Q: Is every 2048-bit IrisCode string equally likely?
A: This is not known, but if not, then the usable entropy situation is even worse. The best estimate for iris entropy is 250 bits, by a degrees of freedom argument (Daugman 2004). All experiments have shown that no two people have very similar irises. If this holds true over the entire population then it is reasonable to assume the iris distribution is flat on a subset of {0,1}^2048. Estimating the strength of a biometric is difficult. 


