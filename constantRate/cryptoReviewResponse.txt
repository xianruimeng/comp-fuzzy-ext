Thank you for the reviews and useful feedback.

We use irises to motivate why working for negative minimum usable entropy is important. Specifically, biometrics provided the original motivation for fuzzy extractors, irises are the best known biometric via IrisCode, and yet IrisCode has negative minimum usable entropy.

However, our constructions do not currently provide security for irises. We believe we provide the first steps in that direction, by finding techniques that rely on specific properties of a distribution (because we know techniques that work for all distribution of a given entropy cannot be used in the case of negative usable entropy).

Q: Length of the key?
A: In the computational setting, a key can be expanded arbitrarily using a PRG, so the length does not matter much. To get enough length for an initial seed, our constructions can be run multiple times (something that's not possible with information-theoretic constructions). As written, key length of the first construction (4.1) is linear in the number of symbols (not bits) in the input, and key length of the second construction (5.2) is arbitrary polynomial in the security parameter, which we get to choose.

Q: Practicality of large alphabet and hope for smaller
A: Indeed, large alphabet is a limitation of our work. Large alphabets do occur in applications: for example, fingerprints (but the metric is more complex than Hamming) or "movie lists" from Juels-Sudan (the metric is set difference). We note that our second construction works for an arbitrary size alphabet, but only achieves negative usable entropy for large alphabets because of limited error-tolerance. This provides hope that the alphabet size can be reduced.  The main obstacle is increasing our supported error tolerance.  

Q: Heavy-duty machinery/Efficiency
A: Point obfuscation need not be heavy-duty: for example, it is reasonable to assume that a cryptographic hash function already works (it certainly does in the RO model). As another example, Canetti-Dakdouk build it from Diffie-Hellman with just on exponentiation. So k hashes or exponentiations are reasonable efficiency estimates.

Q: Length of p
A: k obfuscations (e.g., hash values or pairs of group elements). The second construction also stores the sampling bits, \omega(\log^2 k) per key bit (but we can use more efficient samplers).

Q: Is every 2048-bit IrisCode string equally likely?
A: This is not known, but if not, then usable entropy situation is even worse. The best estimate for iris entropy is 250 bits, by a degrees of freedom argument (Daugman 2004). All experiments have shown that no two people have very similar irises. If this holds true over the entire population then it is reasonable to assume the iris distribution is flat on a subset of {0,1}^2048. Estimating the strength of a biometric is difficult. Irises are believed to be the “best,” based on our current understanding of human development and measurement techniques.  


